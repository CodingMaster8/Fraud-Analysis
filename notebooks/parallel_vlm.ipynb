{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "import asyncio\n",
    "\n",
    "# Get the notebook's directory and navigate up to the project root\n",
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent  # Goes up two levels \n",
    "\n",
    "# Add project root to Python path if not already there\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.vlm_models.analyzer import VLMAnalyzer\n",
    "from src.vlm_models.config import VLMConfig\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ba47b",
   "metadata": {},
   "source": [
    "## FRAUD TESTING VLM\n",
    "### Analyze for each VLM Models all Fraud data tests\n",
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c75392",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Users/Pablo.Vargas2/Documents/isitreal-pablo/data/fraudulent\")\n",
    "\n",
    "image_files = (\n",
    "    list(data_dir.glob(\"*.jpg\")) + \n",
    "    list(data_dir.glob(\"*.jpeg\")) + \n",
    "    list(data_dir.glob(\"*.png\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8757e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelProvider = [\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-5\",\n",
    "    \"gpt-5-chat\",\n",
    "    \"claude-4-5-sonnet\",\n",
    "    \"claude-4-5-haiku\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"qwen-3-vl\",\n",
    "]\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\" / \"vlm_analysis\" / \"fraud\"\n",
    "\n",
    "for model in ModelProvider:\n",
    "    print(f\"Analyzing with model provider: {model}\")\n",
    "    config = VLMConfig(model_provider=model)\n",
    "    analyzer = VLMAnalyzer(config=config, save_dir=OUTPUT_DIR)\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    results_parallel = analyzer.analyze_batch_parallel(\n",
    "        image_files,\n",
    "        max_workers=20\n",
    "    )\n",
    "    parallel_time = time.time() - start\n",
    "    \n",
    "    print(f\"Completed analysis with {model} in {parallel_time} seconds.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3f34e",
   "metadata": {},
   "source": [
    "### Test with cropped cheuque images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb975e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Users/Pablo.Vargas2/Documents/isitreal-pablo/output/extracted_cheques/fraudulent\")\n",
    "\n",
    "image_files = (\n",
    "    list(data_dir.glob(\"*.jpg\")) + \n",
    "    list(data_dir.glob(\"*.jpeg\")) + \n",
    "    list(data_dir.glob(\"*.png\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelProvider = [\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-5\",\n",
    "    \"gpt-5-chat\",\n",
    "    \"claude-4-5-sonnet\",\n",
    "    \"claude-4-5-haiku\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"qwen-3-vl\",\n",
    "]\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\" / \"vlm_analysis_cheques\" / \"fraud\"\n",
    "\n",
    "for model in ModelProvider:\n",
    "    print(f\"Analyzing with model provider: {model}\")\n",
    "    config = VLMConfig(model_provider=model)\n",
    "    analyzer = VLMAnalyzer(config=config, save_dir=OUTPUT_DIR)\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    results_parallel = analyzer.analyze_batch_parallel(\n",
    "        image_files,\n",
    "        max_workers=20\n",
    "    )\n",
    "    parallel_time = time.time() - start\n",
    "    \n",
    "    print(f\"Completed analysis with {model} in {parallel_time} seconds.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f286d208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
